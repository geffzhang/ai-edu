Copyright © Microsoft Corporation. All rights reserved.
适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 学习要点

 用一元线性回归问题理解损失函数、梯度下降、反向传播。

# 提出问题

在互联网建设初期，各大运营商需要解决的问题就是保证服务器所在的机房的温度，保持在23摄氏度左右。那么一个机房安装多少台空调或者提供多大功率的空调合适呢？这个东西虽然能通过热力学计算得到公式，但是总会有误差。因此人们往往会在机房里装一个温控器，来控制空调的开关或者风扇的转速或者制冷能力。更先进的做法是直接把机房建在海底，用海水冷却。

通过一些统计数据，我们得到了这张表格：

|样本序号|1|2|3|...|200|
|---|---|---|---|---|---|
|服务器数量(千台)|0.928|0.0469|0.855|...|0.373|
|空调功率(千瓦)|4.824|2.950|4.643|...|3.594|

### 问题：在一个新建的机房里，如果有346台服务器，我们如何配置空调的功率？

这个数据是二维的，所以我们可以用可视化的方式来展示：
<img src="./Images/4/Data.png"/>

于是，我们把热力学计算的问题转换成为了一个统计问题，因为实在是不能确定每块电路板或每台机器到底能产生多少热量。通过对上图的观察，我们可以判断它属于一个线性回归问题，而且是最简单的一元线性回归。

# 下载训练数据

[点击下载训练数据X](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/TemperatureControlXData.dat)

[点击下载标签数据Y](https://github.com/Microsoft/ai-edu/tree/master/B-%E6%95%99%E5%AD%A6%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/B6-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/Data/TemperatureControlYData.dat)

请把数据拷贝到你的python文件运行的当前目录。以下代码是读取该数据文件的函数，返回值是两个(200,)的列向量。

```Python
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def ReadData():
    Xfile = Path(x_data_name)
    Yfile = Path(y_data_name)
    if Xfile.exists() & Yfile.exists():
        X = np.load(Xfile)
        Y = np.load(Yfile)
        return X,Y
    else:
        return None,None

if __name__ == '__main__':
    X, Y = ReadData()
    plt.plot(X,Y,'.')
    plt.show()
```

# 线性回归

铁柱：木头同学，你还记得什么是线性回归吗？

木头：记得！回归的目的是通过几个已知数据来预测另一个数值型数据的目标值。假设特征和结果满足线性关系，即满足一个计算公式$y=f(x)$，这个公式的自变量就是已知的数据x，函数值$f(x)$就是要预测的目标值。这个计算公式称为回归方程，得到这个方程的过程就称为回归。线性回归就是假设这个方式是一个线性方程，一个多元一次方程，其形式为：

$$y=a_0+a_1x_1+a_2x_2+\dots+a_kx_k$$

铁柱：记性不错！为了简化起见，我们用一元一次的线性回归来举例，即$z = wx+b$（z,w,x,b都是标量），因为这个函数的形式和神经网络中的$Z = WX + B$（Z,W,X,B等都是矩阵）非常近似，可以起到用简单的原理理解复杂的事情的作用。

- [最小二乘法](4.1-最小二乘法.md)
- [梯度下降法](4.2-梯度下降法.md)
- [神经网络法](4.3-神经网络法.md)
- [梯度下降的三种形式](4.4-梯度下降的三种形式.md)

